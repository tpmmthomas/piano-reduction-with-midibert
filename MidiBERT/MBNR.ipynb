{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b68ae3a-cabf-4cee-b69e-49ff750b113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy\n",
    "from miditoolkit.midi import parser as mid_parser  \n",
    "from miditoolkit.midi import containers as ct\n",
    "from numpy import array, linspace\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from matplotlib.pyplot import plot\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43dd2494-712a-4164-bd29-c4b8c4c88aee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Road map\\n----[requirements]\\n0. install requirement\\n    -- pip install -r requirements.txt\\n\\n----[prepare training data]\\n1. turn training data into (-1,512,4)  \\n    : 512 = input_size, \\n    : 4= size of CP token (includingBar (0=new,1=continue,2=pad),Position,Pitch,Duration)\\n    ** DO NOT concatenate all songs tgt, pad every song and make it divisible by 512\\n    ** pad it with (2,16,86,64)\\n    e.g. [ [song1-0:511],[song1-512:520+pad],[song2-0:511],[song2-512-530+pad].... ]\\n    \\n2. Prepare answer dataset \\n    : (0 = padding, 1 = keep, 2 = discard)\\n* save in .npy format\\n* split in 3 different groups\\n    dataroot= ~/data/CP/\\n    -custom_reduction_train.npy , custom_reduction_train_ans.npy\\n    -custom_reduction_valid.npy , custom_reduction_valid_ans.npy\\n    -custom_reduction_test.npy  , custom_reduction_test_ans.npy\\n\\n    \\n----[start fine tuning]\\n1. cd to ./MidiBERT/CP\\n2. python3 finetune.py --task=reduction  --epochs 1 --ckpt xxxxx (default='result/finetune/pretrain_model.ckpt')\\n* gpu with --cuda_devices 0 (+1)\\n\\n----[eval]\\n1. cd to ./MidiBERT/CP\\n2. python3 eval.py --task=reduction\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Road map\n",
    "----[requirements]\n",
    "0. install all requirements\n",
    "    -- pip install -r requirements.txt\n",
    "\n",
    "----[prepare training data]\n",
    "1. turn training data into (-1,512,4)  \n",
    "    : 512 = input_size, \n",
    "    : 4= size of the CP token (Bar (0=new,1=continue,2=pad),Position,Pitch,Duration)\n",
    "    ** DO NOT concatenate all songs tgt, pad every song and make it divisible by 512\n",
    "    ** pad it with (2,16,86,64)\n",
    "    e.g. [ [song1-0:511],[song1-512:520+pad],[song2-0:511],[song2-512-530+pad]] ==> shape(4,512,4)\n",
    "    \n",
    "2. Prepare answer dataset \n",
    "    : (0 = padding, 1 = keep, 2 = discard)\n",
    "* save it in .npy format\n",
    "* split into 3 different groups\n",
    "    put inside ~/data/CP/\n",
    "    -custom_reduction_train.npy , custom_reduction_train_ans.npy\n",
    "    -custom_reduction_valid.npy , custom_reduction_valid_ans.npy\n",
    "    -custom_reduction_test.npy  , custom_reduction_test_ans.npy\n",
    "    \n",
    "** using  .py\n",
    "    - cd to ./prepare_data/CP\n",
    "    - python main.py --task reduction --input_dir \"../../dataset(orchestra only)\"\n",
    "    >files will be saved at ~/data/CP/\n",
    "    >please move all the files to the correct directory\n",
    "\n",
    "\n",
    "    \n",
    "----[start fine tuning]\n",
    "1. cd to ./MidiBERT/CP\n",
    "2. python3 finetune.py --task=reduction  --epochs 1 --ckpt xxxxx (default='result/finetune/pretrain_model.ckpt')\n",
    "* gpu with --cuda_devices 0 (+1)\n",
    "* if gpu is available and --cpu flag is not set, by default it will be trained on GPU\n",
    "\n",
    "----[eval](not finished yet)\n",
    "1. cd to ./MidiBERT/CP\n",
    "2. python3 eval.py --task=reduction\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1673ff-6a38-4dca-af05-1d4adf991963",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1c19cd-be01-47b5-bf3b-1eb7a5d49f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 512, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training data after tokenization\n",
    "a=np.load('./data/CP/custom.npy') # after tokenization\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e05cb6e-5d2f-4f9b-9a9e-07e29f475c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrsponding ans\n",
    "fake_ans= np.array([[random.randint(1,2) for _ in range(512)] for __ in range(4)])  #random generate\n",
    "fake_ans[3][206:]=0 # random padding\n",
    "fake_ans=fake_ans.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ddf7f8-5613-40d8-901f-493be9f9a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test,train,valid split\n",
    "#assume a[0],a[1],a[2:] are three different songs\n",
    "testX,testY = a[0].reshape(-1,512,4),fake_ans[0].reshape(-1,512)\n",
    "validX,validY = a[1].reshape(-1,512,4),fake_ans[1].reshape(-1,512)\n",
    "trainX,trainY = a[2:].reshape(-1,512,4),fake_ans[2:].reshape(-1,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73287f6c-b6ed-408e-95bb-c4a3ebaa3157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save training data\n",
    "np.save('./data/CP/custom_reduction_train.npy',trainX)\n",
    "np.save('./data/CP/custom_reduction_train_ans.npy',trainY)\n",
    "np.save('./data/CP/custom_reduction_valid.npy',validX)\n",
    "np.save('./data/CP/custom_reduction_valid_ans.npy',validY)\n",
    "np.save('./data/CP/custom_reduction_test.npy',testX)\n",
    "np.save('./data/CP/custom_reduction_test_ans.npy',testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e08b5b6b-7273-4baa-88d4-81a01fbda0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "Loading Dictionary\n",
      "\n",
      "Loading Dataset\n",
      "X_train: (2, 512, 4), X_valid: (1, 512, 4), X_test: (1, 512, 4)\n",
      "y_train: (2, 512), y_valid: (1, 512), y_test: (1, 512)\n",
      "   len of train_loader 1\n",
      "   len of valid_loader 1\n",
      "   len of valid_loader 1\n",
      "\n",
      "Building BERT model\n",
      "   Loading pre-trained model from pretrain_model.ckpt"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anacnda\\envs\\RL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:42<00:00, 42.08s/it]\n",
      "100%|██████████| 1/1 [00:42<00:00, 42.76s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:25<00:00, 25.37s/it]\n",
      "100%|██████████| 1/1 [00:26<00:00, 26.03s/it]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:21<00:00, 21.90s/it]\n",
      "100%|██████████| 1/1 [00:22<00:00, 22.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Creating Finetune Trainer using index layer -1\n",
      "   device: cpu\n",
      "init a fine-tune model, sequence-level task? False\n",
      "\n",
      "Training Start\n",
      "   save model at C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/result/finetune/reduction_\\model.ckpt\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP/\n",
      "1\n",
      "513.0\n",
      "epoch: 1/1 | Train Loss: 1.0158 | Train acc: 0.4937 | Valid Loss: 0.8541 | Valid acc: 0.4971 | Test loss: 0.857 | Test acc: 0.5049\n"
     ]
    }
   ],
   "source": [
    "# start fine tuning\n",
    "! python ./MidiBERT/CP/finetune.py --task=reduction --epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea09a7d-7759-4466-beb9-d96d20bbff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "'''\n",
    "procedure:\n",
    "1. use prepare_data to tokenlize *ONE* song to .npy format\n",
    "    -- it should be saved under ~/data/CP\n",
    "2. cd to ~/MidiBERT/CP\n",
    "3. python eval.py --task reduction --case [file name of the .npy file]\n",
    "3. two mid are generated \n",
    "\n",
    "\n",
    "--[sample]\n",
    "1. put orchestra.mid into testcase folder *(the file should only contain 1 file)*\n",
    "2. cd ./prepare_data/CP\n",
    "3. python .\\main.py --task custom --name testcase1 --input_dir ../../testcase\n",
    "4. cd ../../MidiBERT/CP\n",
    "5. python eval.py --task reduction --case testcase1\n",
    "6. u can find the two files in ~/MidiBERT/CP now\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961f34c3-d27e-4e8e-b4c6-27bb7065e759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'main.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "cd ./prepare_data/CP\n",
    "python main.py --task custom --name testcase1 --input_dir ../../testcase\n",
    "cd ../../CP\n",
    "python eval.py --task reduction --case testcase1\n",
    "cd ../..\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da174e45-1f39-4e8f-bd40-477f55c5be47",
   "metadata": {},
   "source": [
    "# case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bec3c0c-468b-4947-8c20-d4aa5c476c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplease reload the notebook if you hv messed up the working path\\nHow to use: run below\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "please reload the notebook if you hv messed up the working path\n",
    "How to use: run below\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3926aa9b-26bc-4113-a499-a1795ab83dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy\n",
    "from miditoolkit.midi import parser as mid_parser  \n",
    "from miditoolkit.midi import containers as ct\n",
    "from numpy import array, linspace\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from matplotlib.pyplot import plot\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import random\n",
    "import os\n",
    "def get_length(m):\n",
    "    mido_obj = mid_parser.MidiFile(m)\n",
    "    notes = [] \n",
    "    for instrument in mido_obj.instruments:\n",
    "        for note in instrument.notes:\n",
    "            notes.append(note)\n",
    "    return len(notes)\n",
    "def read_midi(path):\n",
    "    mido_obj = mid_parser.MidiFile(path)\n",
    "    tick_per_beat = mido_obj.ticks_per_beat\n",
    "\n",
    "    notes = [] \n",
    "    for instrument in mido_obj.instruments:\n",
    "        for note in instrument.notes:\n",
    "            notes.append(note)\n",
    "\n",
    "    # sort by start time\n",
    "    notes.sort(key=lambda note:note.start)\n",
    "    return notes,tick_per_beat\n",
    "\n",
    "def write_midi(notes,tick_per_beat=480,path='out.mid'):\n",
    "    out = mid_parser.MidiFile()\n",
    "    out.ticks_per_beat = tick_per_beat\n",
    "    out.instruments = [ct.Instrument(program=0,is_drum=False,name='post-processed piano')]\n",
    "    for note in notes:\n",
    "        assert(note.velocity)\n",
    "        out.instruments[0].notes.append(ct.Note(start=note.start,end=note.end,pitch=note.pitch,velocity=note.velocity))\n",
    "    out.dump(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ddb0dd5-785c-4efd-b564-9232b5f78ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=read_midi('token2mid.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c6df47-079f-4781-afb9-23bdb354c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "print(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad240f8c-95d0-4779-bffd-9aca70c1a562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\tokah\\\\Documents\\\\MIDI-BERT'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e29721-8756-4d3f-9829-85eb61b962d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file inside casestudySamples folder\n",
    "file='InTheHallOfTheMountainKing.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921c0908-8b71-46c3-b101-68f73c47b757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\n"
     ]
    }
   ],
   "source": [
    "%cd {base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a753435-c24b-4f21-a884-86ccec9b7ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\testcase\n",
      "複製了         1 個檔案。\n",
      "複製了         1 個檔案。\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\prepare_data\\CP\n",
      "Number of  files: 1\n",
      "Data shape: (12, 512, 4), saved at ../../data/CP\\testcase1.npy\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\\MidiBERT\\CP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 20:41:07,015 - model - INFO - ../../testcase\\InTheHallOfTheMountainKing.mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Dictionary\n",
      "\n",
      "Building BERT model\n",
      "\n",
      "Loading Dataset\n",
      "   len of predict_loader 1\n",
      "\n",
      "Load ckpt from result/finetune/reduction_/model_best.ckpt\n",
      "\n",
      "Creating Finetune Trainer using index layer -1\n",
      "! (12, 512, 4) (12, 512)\n",
      "   device: cpu\n",
      "load a fine-tuned model\n",
      "1\n",
      "1.0\n",
      "reduced 2329 notes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anacnda\\envs\\RL\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "移動         1 個檔案。\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\n",
      "before post-processing 3805 notes\n",
      "Octave Transpose: #notes 3805 transposed 386 notes , skipped 620\n",
      "Merge discrete: merged  370  discrete notes\n",
      "Drop discrete: dropped  0  discrete notes\n",
      "Doubling Simplification: removed doubling 621\n",
      "after post-processing, total notes: 2814, removed 991 notes in total\n",
      "Figure(2000x2000)\n",
      "before post-processing 2814 notes\n",
      "Octave Transpose: #notes 2814 transposed 191 notes , skipped 658\n",
      "Merge discrete: merged  15  discrete notes\n",
      "Drop discrete: dropped  0  discrete notes\n",
      "Doubling Simplification: removed doubling 1\n",
      "after post-processing, total notes: 2798, removed 16 notes in total\n",
      "Figure(2000x2000)\n",
      "before post-processing 2798 notes\n",
      "Octave Transpose: #notes 2798 transposed 64 notes , skipped 634\n",
      "Merge discrete: merged  2  discrete notes\n",
      "Drop discrete: dropped  0  discrete notes\n",
      "Doubling Simplification: removed doubling 0\n",
      "after post-processing, total notes: 2796, removed 2 notes in total\n",
      "Figure(2000x2000)\n",
      "C:\\Users\\tokah\\Documents\\MIDI-BERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "目錄不是空的。\n",
      "子目錄或檔案 InTheHallOfTheMountainKing 已經存在。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "移動         1 個檔案。\n",
      "移動         1 個檔案。\n",
      "移動         1 個檔案。\n",
      "移動         1 個檔案。\n",
      "移動         1 個檔案。\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "#move the testcase from casestudysample to the desired folder\n",
    "%cd ./testcase\n",
    "!del /q *\n",
    "!copy ..\\casestudySamples\\{file} \"./\"\n",
    "!copy ..\\casestudySamples\\{file} \"../\"\n",
    "%cd ../\n",
    "\n",
    "#prepare .npy data\n",
    "%cd ./prepare_data/CP\n",
    "!python .\\main.py --task custom --name testcase1 --input_dir ../../testcase\n",
    "\n",
    "#run reduction\n",
    "%cd ../../MidiBERT/CP\n",
    "!python eval.py --task reduction --case testcase1\n",
    "!move ./reduction.mid ../../reduction.mid\n",
    "\n",
    "#run postprocessing\n",
    "%cd ../..\n",
    "!python postprocessing.py -f reduction.mid\n",
    "%cd {base_dir}\n",
    "a,b=read_midi('./testcase/'+file)\n",
    "write_midi(a,b,'merged_orchestra.mid')\n",
    "\n",
    "#token2mid\n",
    "c=np.load('./data/CP/testcase1.npy')\n",
    "out = mid_parser.MidiFile()\n",
    "out.ticks_per_beat = 1024\n",
    "out.instruments = [ct.Instrument(program=0,is_drum=False,name='reduction')]\n",
    "current_beat=-1\n",
    "for idx1,i in enumerate(c):\n",
    "    for idx2,j in enumerate(i):                    \n",
    "        n=c[idx1][idx2]\n",
    "        if n[0]==0:\n",
    "            current_beat+=1\n",
    "        if c[idx1][idx2][0]!=2:\n",
    "            out.instruments[0].notes.append(ct.Note(start=int(current_beat*4*out.ticks_per_beat+n[1]*out.ticks_per_beat/4),\n",
    "                                                    end=int(current_beat*4*out.ticks_per_beat+n[1]*out.ticks_per_beat/4+(n[3]+1)*(out.ticks_per_beat/8)),\n",
    "                                                    pitch=n[2]+22,\n",
    "                                                    velocity=90))\n",
    "out.dump('token2mid.mid')\n",
    "\n",
    "\n",
    "#group files tgt\n",
    "!rmdir /q {file[:-4]}\n",
    "%mkdir {file[:-4]}\n",
    "!echo original_size:{get_length(file)}  -  reduced_size:{get_length('reduction.mid')}  -  postprocessed_size:{get_length('post_processed.mid')} > ./{file[:-4]}/log.txt\n",
    "!move ./reduction.mid ./{file[:-4]}/\n",
    "!move ./token2mid.mid ./{file[:-4]}/\n",
    "!move ./{file} ./{file[:-4]}/\n",
    "!move ./merged_orchestra.mid ./{file[:-4]}/\n",
    "!move ./post_processed.mid ./{file[:-4]}/\n",
    "!echo finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e0cbf-e2e2-4fb1-8ceb-b3cc9cfa0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linux version\n",
    "%cd ./testcase\n",
    "# linus: %rm ./*\n",
    "!rm -f ./*\n",
    "!cp ../casestudySamples/{file} \"./\"\n",
    "!cp ../casestudySamples/{file} \"../\"\n",
    "%cd ../\n",
    "%cd ./prepare_data/CP\n",
    "!python .\\main.py --task custom --name testcase1 --input_dir ../../testcase\n",
    "%cd ../../MidiBERT/CP\n",
    "!python eval.py --task reduction --case testcase1\n",
    "#linux#%mv reduction.mid ../../reduction.mid\n",
    "!mv ./reduction.mid ../../reduction.mid\n",
    "%cd ../..\n",
    "!python postprocessing.py -f reduction.mid\n",
    "%cd base_dir\n",
    "a,b=read_midi('./testcase/'+file)\n",
    "write_midi(a,b,'merged_orchestra.mid')\n",
    "\n",
    "c=np.load('./data/CP/testcase1.npy')\n",
    "out = mid_parser.MidiFile()\n",
    "out.ticks_per_beat = 1024\n",
    "out.instruments = [ct.Instrument(program=0,is_drum=False,name='reduction')]\n",
    "current_beat=-1\n",
    "for idx1,i in enumerate(c):\n",
    "    for idx2,j in enumerate(i):                    \n",
    "        n=c[idx1][idx2]\n",
    "        if n[0]==0:\n",
    "            current_beat+=1\n",
    "\n",
    "\n",
    "        if c[idx1][idx2][0]!=2:\n",
    "            out.instruments[0].notes.append(ct.Note(start=int(current_beat*4*out.ticks_per_beat+n[1]*out.ticks_per_beat/4),\n",
    "                                                    end=int(current_beat*4*out.ticks_per_beat+n[1]*out.ticks_per_beat/4+(n[3]+1)*out.ticks_per_beat/8),\n",
    "                                                    pitch=n[2]+22,\n",
    "                                                    velocity=30))\n",
    "out.dump('token2mid.mid')\n",
    "\n",
    "\n",
    "!rm -r -f {file[:-4]}\n",
    "%mkdir {file[:-4]}\n",
    "!echo original_size:{get_length(file)}\\nreduced_size:{get_length('reduction.mid')}\\npostprocessed_size:{get_length('post_processed.mid')} > ./{file[:-4]}/log.txt\n",
    "!mv ./reduction.mid ./{file[:-4]}/\n",
    "!mv ./token2mid.mid ./{file[:-4]}/\n",
    "!mv ./{file} ./{file[:-4]}/\n",
    "!mv ./merged_orchestra.mid ./{file[:-4]}/\n",
    "!mv ./post_processed.mid ./{file[:-4]}/\n",
    "!echo finished"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24575cee-5e97-4df4-b91e-07ee5cf8307d",
   "metadata": {},
   "source": [
    "# DEBUG "
   ]
  },
  {
   "cell_type": "raw",
   "id": "24fc494e-4d84-49c4-b52f-9f415d17ad2d",
   "metadata": {},
   "source": [
    "with open(r\"./dict/CP.pkl\", \"rb\") as input_file:\n",
    "    e = cPickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31603d08-1be1-4430-aa8c-34cd3b6d69bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=read_midi('./token2mid.mid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fbdcf2-6928-4276-beda-decf8fed9508",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_midi(a,b,'merged_orchestra.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "543bf431-dfaf-4573-924e-dc59ce6b1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.load('./data/CP/testcase1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "450bf21f-0e49-42db-8cea-f66c96041606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a7c20da-c3ef-4600-99af-28fbb233ed9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5957, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a),len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7f79bb2-1280-4826-bbef-63fc1a127ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, 32, 32],\n",
       "       [ 1,  0, 44, 32],\n",
       "       [ 0,  0, 25,  0],\n",
       "       [ 1,  0, 13,  0],\n",
       "       [ 1,  0, 25,  2],\n",
       "       [ 1,  0, 13,  2],\n",
       "       [ 1,  2, 27,  2],\n",
       "       [ 1,  2, 15,  2],\n",
       "       [ 1,  4, 32,  0],\n",
       "       [ 1,  4, 20,  0],\n",
       "       [ 1,  4, 28,  2],\n",
       "       [ 1,  4, 16,  2],\n",
       "       [ 1,  6, 30,  2],\n",
       "       [ 1,  6, 18,  2],\n",
       "       [ 1,  8, 25,  0],\n",
       "       [ 1,  8, 13,  0],\n",
       "       [ 1,  8, 32,  2],\n",
       "       [ 1,  8, 20,  2],\n",
       "       [ 1, 10, 28,  2],\n",
       "       [ 1, 10, 16,  2],\n",
       "       [ 1, 12, 32,  0],\n",
       "       [ 1, 12, 20,  0],\n",
       "       [ 1, 12, 32,  6],\n",
       "       [ 1, 12, 20,  6],\n",
       "       [ 0,  0, 25,  0],\n",
       "       [ 1,  0, 13,  0],\n",
       "       [ 1,  0, 31,  2],\n",
       "       [ 1,  0, 19,  2],\n",
       "       [ 1,  2, 27,  2],\n",
       "       [ 1,  2, 15,  2],\n",
       "       [ 1,  4, 32,  0],\n",
       "       [ 1,  4, 20,  0],\n",
       "       [ 1,  4, 31,  6],\n",
       "       [ 1,  4, 19,  6],\n",
       "       [ 1,  8, 25,  0],\n",
       "       [ 1,  8, 13,  0],\n",
       "       [ 1,  8, 30,  2],\n",
       "       [ 1,  8, 18,  2],\n",
       "       [ 1, 10, 26,  2],\n",
       "       [ 1, 10, 14,  2],\n",
       "       [ 1, 12, 32,  0],\n",
       "       [ 1, 12, 20,  0],\n",
       "       [ 1, 12, 30,  6],\n",
       "       [ 1, 12, 18,  6],\n",
       "       [ 0,  0, 25,  0],\n",
       "       [ 1,  0, 13,  0],\n",
       "       [ 1,  0, 25,  2],\n",
       "       [ 1,  0, 13,  2],\n",
       "       [ 1,  2, 27,  2],\n",
       "       [ 1,  2, 15,  2]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f1daee3-01f0-43d1-b7c7-6e530e37df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mid_parser.MidiFile()\n",
    "out.ticks_per_beat = 1024\n",
    "out.instruments = [ct.Instrument(program=0,is_drum=False,name='reduction')]\n",
    "current_beat=-1\n",
    "for idx1,i in enumerate(c):\n",
    "    for idx2,j in enumerate(i):                    \n",
    "        n=c[idx1][idx2]\n",
    "        if n[0]==0:\n",
    "            current_beat+=1\n",
    "\n",
    "\n",
    "        if c[idx1][idx2][0]!=2:\n",
    "            out.instruments[0].notes.append(ct.Note(start=int(current_beat*4*out.ticks_per_beat+n[1]*out.ticks_per_beat/4),\n",
    "                                                    end=int(current_beat*4*out.ticks_per_beat+n[1]*out.ticks_per_beat/4+n[3]*out.ticks_per_beat/8),\n",
    "                                                    pitch=n[2]+22,\n",
    "                                                    velocity=30))\n",
    "out.dump('token2mid.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f25873e0-059e-426e-b6aa-4254f9cefa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, 60, 14],\n",
       "       [ 1,  0, 66, 14],\n",
       "       [ 1,  0, 48, 14],\n",
       "       [ 1,  0, 54, 14],\n",
       "       [ 1,  0, 38, 19],\n",
       "       [ 1,  0, 48,  7],\n",
       "       [ 1,  0, 45, 14],\n",
       "       [ 1,  0, 48, 14],\n",
       "       [ 1,  0, 26, 19],\n",
       "       [ 1,  0, 54,  7]])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "edd5d664-0375-44f7-b713-4cc87813f158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Note(start=481, end=711, pitch=82, velocity=55),\n",
       " Note(start=481, end=711, pitch=88, velocity=55),\n",
       " Note(start=482, end=712, pitch=70, velocity=70),\n",
       " Note(start=482, end=712, pitch=76, velocity=70),\n",
       " Note(start=482, end=782, pitch=60, velocity=82),\n",
       " Note(start=482, end=602, pitch=70, velocity=42),\n",
       " Note(start=483, end=713, pitch=70, velocity=70),\n",
       " Note(start=483, end=713, pitch=67, velocity=70),\n",
       " Note(start=484, end=784, pitch=48, velocity=82),\n",
       " Note(start=484, end=604, pitch=76, velocity=42)]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4027d33d-452d-4708-94b4-f7902ecdaa39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Note(start=0, end=1792, pitch=82, velocity=30),\n",
       " Note(start=0, end=1792, pitch=88, velocity=30),\n",
       " Note(start=0, end=1792, pitch=70, velocity=30),\n",
       " Note(start=0, end=1792, pitch=76, velocity=30),\n",
       " Note(start=0, end=2432, pitch=60, velocity=30),\n",
       " Note(start=0, end=896, pitch=70, velocity=30),\n",
       " Note(start=0, end=1792, pitch=67, velocity=30),\n",
       " Note(start=0, end=1792, pitch=70, velocity=30),\n",
       " Note(start=0, end=2432, pitch=48, velocity=30),\n",
       " Note(start=0, end=896, pitch=76, velocity=30)]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.instruments[0].notes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5671eb7-1d42-4a18-8e6c-ffe629bc5de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
